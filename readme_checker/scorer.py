"""
ä¿¡ä»»è¯„åˆ†å™¨æ¨¡å— - æ ¹æ®è¿è§„æƒ…å†µè®¡ç®—ä¿¡ä»»åˆ†æ•°

è¯„åˆ†è§„åˆ™ï¼š
- åŸºç¡€åˆ† 100 åˆ†
- æ¯ä¸ªè¿è§„æ‰£é™¤ç›¸åº”åˆ†æ•°
- æœ€ç»ˆåˆ†æ•°é™åˆ¶åœ¨ 0-100 èŒƒå›´å†…

V3 å¢å¼ºï¼š
- åŠ æƒè¯„åˆ†ï¼šæ ¹æ®ä¸¥é‡ç¨‹åº¦å’Œç±»åˆ«åŠ æƒ
- æ¯”è¾ƒä¸Šä¸‹æ–‡ï¼šæä¾›æœ‰æ„ä¹‰çš„è¯„åˆ†è§£é‡Š
"""

from dataclasses import dataclass
from typing import Optional

from readme_checker.verifier import VerificationResult, Violation

# V3: Import weighted scorer
try:
    from readme_checker.metrics.scoring import WeightedTrustScorer, TrustScore
    WEIGHTED_SCORER_AVAILABLE = True
except ImportError:
    WEIGHTED_SCORER_AVAILABLE = False
    WeightedTrustScorer = None  # type: ignore
    TrustScore = None  # type: ignore


# ============================================================
# é…ç½®å¸¸é‡
# ============================================================

# è¿è§„æ‰£åˆ†æƒé‡
SCORING_WEIGHTS: dict[str, int] = {
    "ecosystem": -15,   # ç¼ºå°‘é…ç½®æ–‡ä»¶
    "path": -10,        # æ–­å¼€çš„é“¾æ¥/å›¾ç‰‡
    "command": -10,     # ä¸å­˜åœ¨çš„è„šæœ¬
    "hype": -5,         # å¤¸å¤§æè¿°
    "todo": -5,         # TODO é™·é˜±
}

# è¯„çº§é˜ˆå€¼
SCORE_THRESHOLDS: dict[str, int] = {
    "trustworthy": 80,  # >= 80 åˆ†ï¼šå¯ä¿¡èµ–
    "suspicious": 50,   # 50-79 åˆ†ï¼šå¯ç–‘
    "liar": 0,          # < 50 åˆ†ï¼šéª—å­
}

# è¯„çº§æè¿°
RATING_DESCRIPTIONS: dict[str, str] = {
    "trustworthy": "Trustworthy âœ…",
    "suspicious": "Suspicious ğŸ¤¨",
    "liar": "Liar Detected ğŸš¨",
}

# è¯„çº§ emoji
RATING_EMOJIS: dict[str, str] = {
    "trustworthy": "âœ…",
    "suspicious": "ğŸ¤¨",
    "liar": "ğŸ’©",
}


# ============================================================
# æ•°æ®æ¨¡å‹
# ============================================================

@dataclass
class ScoreBreakdown:
    """
    è¯„åˆ†æ˜ç»†
    
    Attributes:
        base_score: åŸºç¡€åˆ†ï¼ˆ100ï¼‰
        ecosystem_penalty: ç”Ÿæ€ç³»ç»Ÿè¿è§„æ‰£åˆ†
        path_penalty: è·¯å¾„è¿è§„æ‰£åˆ†
        command_penalty: å‘½ä»¤è¿è§„æ‰£åˆ†
        hype_penalty: å¤¸å¤§æè¿°æ‰£åˆ†
        todo_penalty: TODO é™·é˜±æ‰£åˆ†
        total_score: æœ€ç»ˆå¾—åˆ†ï¼ˆ0-100ï¼‰
        rating: è¯„çº§ï¼ˆtrustworthy, suspicious, liarï¼‰
        rating_description: è¯„çº§æè¿°
    """
    base_score: int = 100
    ecosystem_penalty: int = 0
    path_penalty: int = 0
    command_penalty: int = 0
    hype_penalty: int = 0
    todo_penalty: int = 0
    total_score: int = 100
    rating: str = "trustworthy"
    rating_description: str = "Trustworthy âœ…"


# ============================================================
# è¯„åˆ†å‡½æ•°
# ============================================================

def _count_violations_by_category(
    violations: list[Violation],
) -> dict[str, int]:
    """
    æŒ‰ç±»åˆ«ç»Ÿè®¡è¿è§„æ•°é‡
    
    Args:
        violations: è¿è§„åˆ—è¡¨
    
    Returns:
        ç±»åˆ« -> æ•°é‡çš„æ˜ å°„
    """
    counts: dict[str, int] = {}
    for v in violations:
        counts[v.category] = counts.get(v.category, 0) + 1
    return counts


def _get_rating(score: int) -> str:
    """
    æ ¹æ®åˆ†æ•°è·å–è¯„çº§
    
    Args:
        score: ä¿¡ä»»åˆ†æ•°
    
    Returns:
        è¯„çº§å­—ç¬¦ä¸²
    """
    if score >= SCORE_THRESHOLDS["trustworthy"]:
        return "trustworthy"
    elif score >= SCORE_THRESHOLDS["suspicious"]:
        return "suspicious"
    else:
        return "liar"


def calculate_score(result: VerificationResult) -> ScoreBreakdown:
    """
    è®¡ç®—ä¿¡ä»»åˆ†æ•°
    
    Args:
        result: éªŒè¯ç»“æœ
    
    Returns:
        ScoreBreakdown å¯¹è±¡ï¼ŒåŒ…å«è¯„åˆ†æ˜ç»†
    """
    breakdown = ScoreBreakdown()
    
    # ç»Ÿè®¡å„ç±»è¿è§„
    counts = _count_violations_by_category(result.violations)
    
    # è®¡ç®—å„ç±»æ‰£åˆ†
    breakdown.ecosystem_penalty = counts.get("ecosystem", 0) * SCORING_WEIGHTS["ecosystem"]
    breakdown.path_penalty = counts.get("path", 0) * SCORING_WEIGHTS["path"]
    breakdown.command_penalty = counts.get("command", 0) * SCORING_WEIGHTS["command"]
    breakdown.hype_penalty = counts.get("hype", 0) * SCORING_WEIGHTS["hype"]
    breakdown.todo_penalty = counts.get("todo", 0) * SCORING_WEIGHTS["todo"]
    
    # è®¡ç®—æ€»åˆ†
    total_penalty = (
        breakdown.ecosystem_penalty +
        breakdown.path_penalty +
        breakdown.command_penalty +
        breakdown.hype_penalty +
        breakdown.todo_penalty
    )
    
    # é™åˆ¶åœ¨ 0-100 èŒƒå›´å†…
    breakdown.total_score = max(0, min(100, breakdown.base_score + total_penalty))
    
    # ç¡®å®šè¯„çº§
    breakdown.rating = _get_rating(breakdown.total_score)
    breakdown.rating_description = RATING_DESCRIPTIONS[breakdown.rating]
    
    return breakdown


# ============================================================
# V3: Weighted Scoring Functions
# ============================================================

def calculate_score_v3(result: VerificationResult) -> "TrustScore":
    """
    V3: ä½¿ç”¨åŠ æƒè¯„åˆ†å™¨è®¡ç®—ä¿¡ä»»åˆ†æ•°
    
    æ ¹æ®è¿è§„çš„ä¸¥é‡ç¨‹åº¦å’Œç±»åˆ«è¿›è¡ŒåŠ æƒè®¡ç®—ã€‚
    
    Args:
        result: éªŒè¯ç»“æœ
    
    Returns:
        TrustScore å¯¹è±¡
    """
    if not WEIGHTED_SCORER_AVAILABLE:
        # Fallback to legacy
        breakdown = calculate_score(result)
        return type('TrustScore', (), {
            'score': float(breakdown.total_score),
            'grade': 'A' if breakdown.total_score >= 90 else 'B' if breakdown.total_score >= 80 else 'C' if breakdown.total_score >= 70 else 'D' if breakdown.total_score >= 60 else 'F',
            'total_issues': len(result.violations),
            'critical_issues': sum(1 for v in result.violations if v.severity == 'error'),
            'warning_issues': sum(1 for v in result.violations if v.severity == 'warning'),
            'info_issues': sum(1 for v in result.violations if v.severity == 'info'),
            'breakdown': {},
            'comparative_context': breakdown.rating_description,
        })()
    
    scorer = WeightedTrustScorer()
    
    # Convert violations to dict format
    violations_dicts = [
        {
            'category': v.category,
            'severity': v.severity,
            'message': v.message,
        }
        for v in result.violations
    ]
    
    total_claims = (
        result.stats.get('ecosystem_claims', 0) +
        result.stats.get('path_claims', 0) +
        result.stats.get('module_claims', 0)
    )
    
    return scorer.calculate(violations_dicts, total_claims)
